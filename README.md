# prefixopt

## Описание

`prefixopt` - это инструмент для сетевых инженеров и специалистов по безопасности. Он позволяет автоматизировать рутинные задачи по обработке списков IP-адресов: удаление дубликатов, агрегацию подсетей, фильтрацию мусора (Bogons), поиск пересечений, симантическое сравнение списков, а также иключение одного или больше подсетей/адресов из списка.

Позволяет привести в порядок разрозненные списки IP-адресов:
- Оптимизация: Автоматическое удаление дубликатов и вложенных сетей (например, удаление /32, если есть покрывающая /24).
- Агрегация: Объединение смежных подсетей в суперсети (CIDR summarization).
- Фильтрация: Очистка списков от Bogons, частных сетей (RFC1918), Loopback и Multicast.
- Вычитание (Exclude): Исключение конкретных адресов или подсетей из общего списка с автоматическим разбиением диапазонов.
- Сравнение (Diff): Семантическое сравнение двух списков (показывает, какие подсети были добавлены или удалены).
- Всеядность: Парсер автоматически извлекает префиксы из любых текстовых файлов (логи, конфигурации оборудования, CSV, JSON).

---

## Установка

Требуется Python 3.9 или выше.

```bash
# Клонирование репозитория
git clone https://github.com/ReuxM13/prefixopt.git
cd prefixopt

# Создание и активация виртуального окружения (опционально)
python -m venv venv

# Активация venv
.\venv\Scripts\activate # Windows
source venv/bin/activate # Linux

# Установка в режиме разработки (рекомендуется)
pip install -e .
```

---

## Техническая реализация

Архитектура построена на модульном принципе (Core / CLI / Data).

- Производительность: Используются алгоритмы линейной сложности O(N) для удаления вложенности и агрегации (на базе стека), что позволяет обрабатывать часть (до 10 млн строк) BGP Full View таблицы за несколько минут.
- Память: Чтение и фильтрация данных реализованы через генераторы (Lazy Evaluation) для минимизации потребления RAM.
- Безопасность: Внутри пайплайна работа идет только с объектами IPv4Network/IPv6Network, строковые операции исключены. Реализованы жесткие лимиты (Hard Limits) на размер входных данных для предотвращения OOM.

### Ограничения
- Memory Overhead: Утилита написана на чистом Python. Из-за накладных расходов на объекты ipaddress, обработка списков объемом более 8-10 млн строк может требовать значительного объема RAM (от 8-10ГБ).
- JSON: Парсинг JSON-файлов не является потоковым - файл загружается в память целиком.
- Big Data: Инструмент не предназначен для обработки больших данных в реальном времени. Это утилита для конфигураций и списков доступа, а не для аналитики трафика.

## Лицензия
Этот проект распространяется под лицензией *MIT License*. См. файл `LICENSE` для подробностей.